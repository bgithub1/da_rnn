{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_PMqdwURMYcQ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1567199946956,
     "user": {
      "displayName": "bill perlman",
      "photoUrl": "",
      "userId": "13261284114599467220"
     },
     "user_tz": 240
    },
    "id": "9up9I4SnMYcV",
    "outputId": "2a0d569f-212a-474e-ea98-f76dbaea090d"
   },
   "outputs": [],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get system home on MAC or Linux\n",
    "SYS_HOME = str(pathlib.Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make batches from 2d matrix m\n",
    "def make_batches(m,ss=20,row_len=None):\n",
    "    rl = m.shape[1] if row_len is None else row_len\n",
    "    x = [m[i:(int((len(m)-i)/ss)*ss)+i].reshape(-1,ss,rl) for i in range(len(m)-ss)]\n",
    "    xx = []\n",
    "    for i in range(len(x)):\n",
    "        xx.extend(x[i].reshape(-1))\n",
    "    input_batches = np.array(xx).reshape(-1,ss,rl)\n",
    "    return input_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59NP5FYhbfY8"
   },
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim,hidden = None, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden = hidden\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        in_var = torch.Tensor(input)\n",
    "        batch_size = in_var.size(1)\n",
    "        if self.hidden is None:\n",
    "          self.hidden = self.init_hidden(batch_size)\n",
    "        lstm_out, self.hidden = self.lstm(in_var,(self.hidden[0].detach(),self.hidden[1].detach()))\n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.linear(lstm_out[-1].view(batch_size, -1))\n",
    "        return y_pred.view(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1567201917352,
     "user": {
      "displayName": "bill perlman",
      "photoUrl": "",
      "userId": "13261284114599467220"
     },
     "user_tz": 240
    },
    "id": "C9rn4_rylSGj",
    "outputId": "da0149a5-732e-468a-d9a2-d8e20683bb95"
   },
   "outputs": [],
   "source": [
    "noise_level = .5\n",
    "cycles = 300\n",
    "x_vals = np.linspace(0,360*cycles,360*cycles/4 + 1)\n",
    "y_vals = np.sin(x_vals*np.pi/180)\n",
    "y_vals = y_vals + np.random.randn(len(y_vals)) * noise_level\n",
    "# df = pd.DataFrame({'x_vals':x_vals,'close':y_vals})\n",
    "# df.iloc[:1000].close.plot.line()\n",
    "plt.plot(y_vals[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1567201919639,
     "user": {
      "displayName": "bill perlman",
      "photoUrl": "",
      "userId": "13261284114599467220"
     },
     "user_tz": 240
    },
    "id": "2h-o4KdKrQ_z",
    "outputId": "b59bc621-36e2-4dbd-ba9a-5aa57cc9fe54"
   },
   "outputs": [],
   "source": [
    "seq_len = 19\n",
    "total_batches = int(len(y_vals)/(seq_len+1))\n",
    "y_vals_2d = y_vals[0:(total_batches*(seq_len+1))].reshape(total_batches,seq_len+1)\n",
    "x_in = y_vals_2d.reshape(total_batches,seq_len+1,1)\n",
    "x_in = np.transpose(x_in,(1,0,2))\n",
    "x_in = x_in[:seq_len,:,:]\n",
    "y_in = y_vals_2d[:,-1].reshape(-1)\n",
    "tests = 50\n",
    "train = total_batches - tests\n",
    "X_train = x_in[:,:train,:]\n",
    "y_train = y_in[:train]\n",
    "X_test = x_in[:,train:,:]\n",
    "y_test = y_in[train:]\n",
    "\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLLgbGv4bjWR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1567200388779,
     "user": {
      "displayName": "bill perlman",
      "photoUrl": "",
      "userId": "13261284114599467220"
     },
     "user_tz": 240
    },
    "id": "Ox463sq7H641",
    "outputId": "ac044347-9f0a-433c-fd70-305b1f3d9ee4"
   },
   "outputs": [],
   "source": [
    "torch.Tensor(X_train).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25575,
     "status": "ok",
     "timestamp": 1567202300849,
     "user": {
      "displayName": "bill perlman",
      "photoUrl": "",
      "userId": "13261284114599467220"
     },
     "user_tz": 240
    },
    "id": "HjGhdEreFlCf",
    "outputId": "1ac89fb9-f14b-4483-b872-ade361678d96"
   },
   "outputs": [],
   "source": [
    "lstm_input_size = X_train.shape[2]\n",
    "h1 = 64\n",
    "output_dim = 1\n",
    "num_layers = 1\n",
    "model = LSTM(lstm_input_size, h1,  output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "num_epochs = 500\n",
    "learning_rate  =.02\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#####################\n",
    "# Train model\n",
    "#####################\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "yt = torch.tensor(y_train,dtype=torch.float32)\n",
    "for t in range(num_epochs):\n",
    "    # Clear stored gradient\n",
    "#     model.zero_grad()\n",
    "        \n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, yt)\n",
    "    if t % 20 == 0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1567202795218,
     "user": {
      "displayName": "bill perlman",
      "photoUrl": "",
      "userId": "13261284114599467220"
     },
     "user_tz": 240
    },
    "id": "66C4sI5JZBcn",
    "outputId": "e95544a5-bc08-4f79-e063-316931e62a8e"
   },
   "outputs": [],
   "source": [
    "# you should see just one line\n",
    "model.hidden = None\n",
    "y_t = model(X_test).data.numpy()\n",
    "plt.plot(y_t.round(5))\n",
    "plt.plot(y_test.round(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md_folder = SYS_HOME + '/Dropbox/market_data'\n",
    "uso_path = f'{md_folder}/stocks/uso.csv'\n",
    "df_uso = pd.read_csv(uso_path)\n",
    "df_uso['year'] = df_uso.timestamp.str.slice(0,4).astype(int)\n",
    "df_uso['month'] = df_uso.timestamp.str.slice(5,7).astype(int)\n",
    "df_uso['day'] = df_uso.timestamp.str.slice(8,10).astype(int)\n",
    "df_uso['hour'] = df_uso.timestamp.str.slice(11,13).astype(int)\n",
    "df_uso['minute'] = df_uso.timestamp.str.slice(14,16).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uso.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uso_2018 = df_uso[df_uso.tradingDay.str.contains('2018')]\n",
    "df_uso_2018 = df_uso_2018[(df_uso_2018.hour>=7) & (df_uso_2018.hour<=17)]\n",
    "# for c in ['close','open','high','low','volume']:\n",
    "#     df_uso_2018[c] = df_uso_2018[c].pct_change()\n",
    "# df_uso_2018 = df_uso_2018.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getm(dfgb):\n",
    "    print(dfgb[['year','month','day']].iloc[0].as_matrix())\n",
    "    return make_batches(dfgb.as_matrix())\n",
    "df2018 = df_uso_2018[['close','open','high','low','volume','year','month','day','hour','minute']]\n",
    "df_matrices = df2018.groupby(['year','month','day']).apply(getm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df2018.groupby(['year','month','day']).get_group((2018, 1, 2))\n",
    "g.shape,make_batches(g.as_matrix()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = []\n",
    "for mmm in df_matrices.values:\n",
    "    mm.extend(mmm)\n",
    "mm = np.array(mm)\n",
    "mm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_uso_2018.close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df_uso_2018[['close','open','high','low','volume','month','day','hour','minute']].as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sequence size\n",
    "ss = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp_len = m.shape[1]\n",
    "x = [m[i:(int((len(m)-i)/ss)*ss)+i].reshape(-1,ss,inp_len) for i in range(len(m)-ss)]\n",
    "xx = []\n",
    "for i in range(len(x)):\n",
    "    if i % 5000 == 0:\n",
    "        print(i)\n",
    "        xx.extend(x[i].reshape(-1))\n",
    "input_batches = np.array(xx).reshape(-1,ss,inp_len)\n",
    "use_pct_change = False\n",
    "if use_pct_change:\n",
    "    a = input_batches[:,1:,:5]/input_batches[:,0:-1,:5] - 1\n",
    "    input_batches = np.concatenate((a,input_batches[:,1:,5:]),axis=2)\n",
    "input_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batches = mm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_predict = 0\n",
    "use_all_features=True\n",
    "if use_all_features:\n",
    "    X_vals = input_batches[:,:-1,:].transpose(1,0,2) # use all features\n",
    "else:\n",
    "    X_vals = input_batches[:,:-1,:1].transpose(1,0,2) # use only the first (like the close)\n",
    "y_vals = input_batches[:,-1,feature_to_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vals.shape,y_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 100000\n",
    "test_size = 100\n",
    "X_train = X_vals[:,:train_size,:]\n",
    "y_train = y_vals[:train_size]\n",
    "X_test = X_vals[:,train_size:(train_size+test_size),:]\n",
    "y_test = y_vals[train_size:(train_size+test_size)]\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_input_size = X_train.shape[2]\n",
    "h1 = 64\n",
    "output_dim = 1\n",
    "num_layers = 1\n",
    "model = LSTM(lstm_input_size, h1,  output_dim=output_dim, num_layers=num_layers)\n",
    "\n",
    "num_epochs = 150\n",
    "init_lr  = .01\n",
    "min_lr = .01\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "\n",
    "#####################\n",
    "# Train model\n",
    "#####################\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "# yt = torch.tensor(y_train,dtype=torch.float32)\n",
    "yt = Variable(torch.from_numpy(y_train).type(torch.FloatTensor))\n",
    "\n",
    "lowest_loss = np.finfo('d').max\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # Clear stored gradient\n",
    "#     model.zero_grad()\n",
    "        \n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    loss = loss_fn(y_pred, yt)\n",
    "    if t % 1 == 0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()\n",
    "        \n",
    "    if loss.item() < lowest_loss:\n",
    "        lowest_loss = loss.item()\n",
    "#     if t % 5 == 0 and t > 0:\n",
    "#         for param_group in optimiser.param_groups:\n",
    "#             if param_group['lr'] > min_lr:\n",
    "#                 param_group['lr'] = param_group['lr'] * 0.9\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred.size()\n",
    "yt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_seq = 1\n",
    "seq_len = 4\n",
    "num_seq = 200000\n",
    "\n",
    "seqs = np.arange(beg_seq,beg_seq+beg_seq*seq_len*num_seq).reshape(-1,l)\n",
    "x_in = a[:,:-1]\n",
    "y_in = a[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in.shape,y_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yearly_std = .2\n",
    "daily_std = .2 / 252**.5\n",
    "y_init = 100\n",
    "steps = 100\n",
    "pct_changes = np.random.choice([-1,1],size=(steps)) * np.random.randn(steps)* daily_std\n",
    "vals = np.concatenate(([y_init],np.zeros(steps-1)))\n",
    "# 100, i-1 * (1+c1),i-1 * (1+c2),i-1 * (1+c3)\n",
    "\n",
    "# 100, \n",
    "# 100 * (1+c1), \n",
    "# (100 * (1+c1)*(1+c2)), \n",
    "# (100 * (1+c1)*(1+c2))* (1+c3)\n",
    "p=1\n",
    "plt.plot([y_init * np.prod([(1+pct_changes[i-p:i])]) for i in range(p,steps)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vals = input_batches[:,:-1,:1].transpose(1,0,2)\n",
    "y_vals = input_batches[:,-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = make_batches(m)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3012.79/36)/((33138.65+24180)) * 2400,(3012.79)/((33138.65+24180)*36) * 2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = .12\n",
    "a = 1\n",
    "[a*r**i for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1-1/12*0,1-1/12,1-1/12*2,1-1/12*3]\n",
    "12*1 - 1*11/2  1(12*11/2)/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "s = [(n-i)/n for i in range(n+1)]\n",
    "sum(s)/len(s),len(s),1/n*np.array([n-i for i in range(n+1)]),s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of sequence_models_tutorial.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/sequence_models_tutorial.ipynb",
     "timestamp": 1567199914628
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
