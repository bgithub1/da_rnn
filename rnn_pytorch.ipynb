{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## rnn_pytorch - This is incomplete as of 04/01/2019\n",
    "#### Use pytorch's nn.RNN to create predictions similar to those predicted by da_rnn.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch import stack as tsk #@UnresolvedImport\n",
    "from torch import optim\n",
    "from torch import from_numpy #@UnresolvedImport\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Define pytorch Module\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size=32):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=hidden_size,     # rnn hidden unit\n",
    "            num_layers=1,       # number of rnn layer\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, x_in, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, hidden_size)\n",
    "        h = None if h_state is None else from_numpy(h_state.numpy().astype(np.float32))\n",
    "        x = from_numpy(x_in.numpy().astype(np.float32))\n",
    "        r_out, h_state = self.rnn(x, h)\n",
    "\n",
    "        outs = []    # save all predictions\n",
    "        for time_step in range(r_out.size(1)):    # calculate output for each time step\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "#         return torch.stack(outs, dim=1), h_state\n",
    "        return tsk(outs, dim=1), h_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Define model runner\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnPytorch():\n",
    "    def __init__(self,\n",
    "        df=None,\n",
    "        reuse_indices_in_batches = True,\n",
    "        epochs = 400,\n",
    "        batch_size = 1, \n",
    "        time_step = 10,\n",
    "        y_col = 'y',\n",
    "        index_col = 'pi',\n",
    "        test_percentage = .2,\n",
    "        learning_rate = .02):\n",
    "        \n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.time_step = time_step\n",
    "        self.y_col = y_col\n",
    "        self.index_col = index_col\n",
    "        self.test_percentage = test_percentage\n",
    "\n",
    "        self.df = self.default_data() if df is None else df.copy()\n",
    "        x_cols = list(filter(lambda c: c!=y_col,self.df.columns.values))\n",
    "        if self.index_col is not None:\n",
    "            x_cols = list(filter(lambda c: c!=self.index_col, x_cols))\n",
    "        self.x_cols = x_cols\n",
    "        \n",
    "        # create member variables\n",
    "        self.rnn = SimpleRNN(len(self.x_cols))\n",
    "        self.optimizer = optim.Adam(self.rnn.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.test_size = len(self.df) - int(len(self.df) * (1-test_percentage))\n",
    "        train_len = int(len(self.df) * (1-self.test_percentage))\n",
    "        df_train_data = self.df.iloc[:train_len]\n",
    "        \n",
    "        self.training_batches = self.create_batches(df_train_data,reuse_indices_in_batches=reuse_indices_in_batches)\n",
    "        dt_test_data = self.df[-self.test_size:]\n",
    "        self.test_batches = self.create_test_data(dt_test_data)\n",
    "        self.df_test = self.test_batches['df_test']\n",
    "        pass\n",
    "        \n",
    "    def create_batches(self,df_train_data,reuse_indices_in_batches=True):\n",
    "        # determine the label column\n",
    "        lc = self.y_col\n",
    "        # determine the columns that are features (x columns) and the column that will have index values\n",
    "        indices = np.array(df_train_data.index)\n",
    "        x_cols = self.x_cols \n",
    "        if self.index_col is not None:\n",
    "#             x_cols = list(filter(lambda c: c!=self.index_col, x_cols))\n",
    "            indices = np.array(df_train_data[self.index_col])\n",
    "        indices = indices.reshape(-1,1)\n",
    "        df_x = df_train_data[x_cols]\n",
    "        df_y = df_train_data[[lc]]\n",
    "        # get x and y\n",
    "        x = df_x.values\n",
    "        y = df_y.values\n",
    "        # now make sure that the length of x is divisible by batch_size * time_step * x_cols\n",
    "        lenx = x.shape[0]\n",
    "        lenx = (lenx // (self.batch_size * self.time_step)) * (self.batch_size * self.time_step)\n",
    "        \n",
    "        x = x[:lenx]\n",
    "        y = y[:lenx]\n",
    "        indices = indices[:lenx]\n",
    "        \n",
    "        if reuse_indices_in_batches:\n",
    "            tsgl = len(indices) -  self.time_step * self.batch_size # time step group length\n",
    "            random_indices = np.random.permutation(tsgl) \n",
    "            x_time_step_groups = np.array([np.array(x[i:i+self.time_step]) for i in range(tsgl)])[random_indices]\n",
    "            x_batches = np.array(x_time_step_groups).reshape(-1,self.batch_size,x_time_step_groups.shape[1],x_time_step_groups.shape[2])\n",
    "            \n",
    "            y_time_step_groups = np.array([y[i:i+self.time_step] for i in range(tsgl)])[random_indices]\n",
    "            y_batches = np.array(y_time_step_groups).reshape(-1,self.batch_size,y_time_step_groups.shape[1],y_time_step_groups.shape[2])\n",
    "            \n",
    "            i_time_step_groups = np.array([indices[i:i+self.time_step] for i in range(tsgl)])[random_indices]\n",
    "            i_batches = np.array(i_time_step_groups).reshape(-1,self.batch_size,i_time_step_groups.shape[1],i_time_step_groups.shape[2])\n",
    "    \n",
    "        else:\n",
    "            x_batches = x.reshape(-1,self.batch_size,self.time_step,len(x_cols))\n",
    "            y_batches = y.reshape(-1,self.batch_size,self.time_step,1)\n",
    "            i_batches = indices.reshape(-1,self.batch_size,self.time_step,1)\n",
    "        training_batches = {'i':i_batches,'x':x_batches,'y':y_batches}   \n",
    "        \n",
    "        return training_batches\n",
    "\n",
    "    def create_test_data(self,df_test_data):\n",
    "        \n",
    "        # create test data to be used when plotting progress\n",
    "        test_batches = self.create_batches(df_test_data,reuse_indices_in_batches=False)\n",
    "        \n",
    "        # create input data for creating predictions that you can plot during training\n",
    "        i_batches_test = test_batches['i']\n",
    "        y_actual_test = test_batches['y']\n",
    "        \n",
    "        # reshape your prediction batches data so that they 1 dimensional arrays that can go into the columns of a DataFrame\n",
    "        i_test = i_batches_test.reshape(-1)\n",
    "        y_test = y_actual_test.reshape(-1)\n",
    "        \n",
    "        # create DataFrame that is used for plotting during training to see progress\n",
    "        df_test = pd.DataFrame({'y_actual':y_test,'y_pred':np.zeros(len(y_test))})\n",
    "        # reset that DataFrame's index \n",
    "        df_test.index = i_test\n",
    "        test_batches['df_test'] = df_test\n",
    "        return test_batches\n",
    "\n",
    "    def plot_it(self,executed_first_plot,h_state):\n",
    "        rnn_validator = self.rnn.eval()\n",
    "        x_batches_test = self.test_batches['x']\n",
    "        i_batches_test = self.test_batches['i']\n",
    "        # use first dimension of x_batches to get the total number of batches\n",
    "        plot_steps = x_batches_test.shape[0]\n",
    "        h_state_temp = h_state\n",
    "        for plot_step in range(plot_steps):\n",
    "            x_batch_test = x_batches_test[plot_step]\n",
    "            x_batch_test_tensor = from_numpy(x_batch_test)    # shape (batch, time_step, input_size)\n",
    "            test_predict,h_state_temp = rnn_validator(x_batch_test_tensor,h_state_temp)\n",
    "            h_state_temp = h_state_temp.data\n",
    "            y_predictions = test_predict.data.numpy().reshape(-1)\n",
    "            indices_for_y_predictions = i_batches_test[plot_step].reshape(-1) \n",
    "            self.df_test.loc[indices_for_y_predictions,'y_pred'] = y_predictions\n",
    "        df_display = self.df_test.iloc[-100:]\n",
    "        if not executed_first_plot:\n",
    "            self.line1, = self.ax.plot(df_display.index, df_display.y_actual, 'r-')\n",
    "            self.line2, = self.ax.plot(df_display.index, df_display.y_pred, 'b-')\n",
    "            executed_first_plot = True\n",
    "        else:\n",
    "            self.line1.set_ydata(df_display.y_actual)\n",
    "            self.line2.set_ydata(df_display.y_pred)\n",
    "            self.fig.canvas.start_event_loop(0.05)\n",
    "\n",
    "    def default_data(self):\n",
    "        time_steps = self.time_step\n",
    "        epochs = self.epochs\n",
    "        # show data\n",
    "        steps = np.linspace(0, np.pi*epochs, epochs*time_steps, dtype=np.float32)  # float32 for converting torch FloatTensor\n",
    "        x_np = np.sin(steps)\n",
    "        y_np = np.cos(steps)\n",
    "        dff = pd.DataFrame({'pi':steps,'x':x_np,'y':y_np})\n",
    "        return dff\n",
    "\n",
    "    def run(self):\n",
    "        plt.figure(1, figsize=(12, 5))\n",
    "        plt.ion()           # continuously plot\n",
    "        steps = self.training_batches['i'].shape[0] \n",
    "        self.fig = plt.figure()\n",
    "        self.ax = plt.gca()\n",
    "        executed_first_plot=False\n",
    "        \n",
    "        h_state = None      # for initial hidden state\n",
    "        for step in range(steps):\n",
    "            \n",
    "    #         i_np,x_np,y_np = create_mini_batches(batches, [step])\n",
    "            i_np,x_np,y_np = self.training_batches['i'][step],self.training_batches['x'][step],self.training_batches['y'][step]\n",
    "            \n",
    "            x = torch.Tensor(x_np)    # shape (batch, time_step, input_size)\n",
    "            y = torch.Tensor(y_np)\n",
    "        \n",
    "            prediction, h_state = self.rnn(x, h_state)   # rnn output\n",
    "            # !! next step is important !!\n",
    "            h_state = h_state.data        # repack the hidden state, break the connection from last iteration\n",
    "        \n",
    "            loss = self.loss_func(prediction, y)         # calculate loss\n",
    "            if float(loss.data[0]<.00002):\n",
    "                print(f'plotting step {step}.  loss = {loss.data[0]}')\n",
    "                self.plot_it(executed_first_plot,h_state)\n",
    "                executed_first_plot = True\n",
    "                break\n",
    "            self.optimizer.zero_grad()                   # clear gradients for this training step\n",
    "            loss.backward()                         # backpropagation, compute gradients\n",
    "            self.optimizer.step()                        # apply gradients\n",
    "    \n",
    "            if step % 20 == 0: \n",
    "                print(f'plotting step {step}.  loss = {loss.data[0]}')\n",
    "                self.plot_it(executed_first_plot,h_state)\n",
    "                executed_first_plot = True\n",
    "                    \n",
    "        print('done')\n",
    "        plt.ioff()\n",
    "        input('hit return to exit')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Define main method\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    df_uso = pd.read_csv('./data/uso_201812.csv')\n",
    "    #close    high    low    open    symbol    timestamp    tradingDay    volume\n",
    "    df_uso = df_uso[['open','high','low','close','volume','tradingDay']]\n",
    "    df_uso['year'] = df_uso.tradingDay.apply(lambda d:int(str(d)[0:4]))\n",
    "    df_uso['month'] = df_uso.tradingDay.apply(lambda d:int(str(d)[5:7]))\n",
    "    df_uso['day'] = df_uso.tradingDay.apply(lambda d:int(str(d)[8:10]))\n",
    "    df_uso = df_uso[['open','high','low','close','volume','year','month','day']]\n",
    "    df_uso['ic'] = df_uso.index\n",
    "    df_uso['y'] = df_uso.iloc[1:].close\n",
    "    df_uso = df_uso[1:]\n",
    "    rnnpy = RnnPytorch(df = df_uso,index_col='ic',\n",
    "                       reuse_indices_in_batches=True,epochs = 100000,batch_size=10)\n",
    "#     rnnpy.df.to_csv('./df_rnn_pytorch.csv',index=False)\n",
    "    rnnpy.run()\n",
    "\n",
    "    print('done done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_uso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
